{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import os.path as osp\n",
    "sys.path\n",
    "sys.path.append('./L1DeepMETv2/')\n",
    "from graphmetnetwork import GraphMetNetwork\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.data import DataLoader\n",
    "import model.net as net\n",
    "import model.data_loader as data_loader\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './L1DeepMETv2/data_ttbar'\n",
    "dataloaders = data_loader.fetch_dataloader(data_dir = data_dir, batch_size=1, validation_split=.2)\n",
    "test_dl = dataloaders['test']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Test dataloader: {}'.format(len(test_dl)))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a sample test data point from the test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = None\n",
    "for cnt, test_data in enumerate(test_dl):\n",
    "    if cnt == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tensor Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_cont = 6\n",
    "x_cont_test = test_data.x[:,:n_features_cont] .to(device)  # include puppi\n",
    "x_cat_test = test_data.x[:,n_features_cont:].long().to(device)\n",
    "etaphi_test = torch.cat([test_data.x[:, 3][:, None], test_data.x[:, 4][:, None]], dim=1).to(device=device)\n",
    "batch_test = test_data.batch.to(device)\n",
    "edge_index_test = radius_graph(etaphi_test, r=0.4, batch=batch_test, loop=False, max_num_neighbors=255).to(device=device)\n",
    "print(f'x_cont_test: {x_cont_test.shape}')\n",
    "print(f'x_cat_test: {x_cat_test.shape}')\n",
    "print(f'etaphi: {etaphi_test.shape}')\n",
    "print(f'batch: {batch_test.shape}')\n",
    "print(f'edge_index: {edge_index_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Tensor parameters to Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cont = np.ascontiguousarray(x_cont_test.squeeze(0).cpu().numpy())\n",
    "x_cat = np.ascontiguousarray(x_cat_test.squeeze(0).cpu().numpy())\n",
    "batch = np.ascontiguousarray(batch_test.squeeze(0).cpu().numpy())\n",
    "etaphi = etaphi_test.squeeze(0).cpu().numpy()\n",
    "edge_index = edge_index_test.squeeze(0).cpu().numpy().transpose()\n",
    "num_nodes = x_cont.shape[0]\n",
    "batch_size = batch.shape[0]\n",
    "print(f'Number of nodes: {num_nodes}')\n",
    "assert(num_nodes == batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = './L1DeepMETv2/ckpts_April30_scale_sigmoid'\n",
    "restore_ckpt = osp.join(prefix, 'last.pth.tar')\n",
    "norm = torch.tensor([1., 1., 1., 1., 1., 1.]).to(device=device)\n",
    "torch_model = net.Net(continuous_dim=6, categorical_dim=2 , norm=norm).to(device)\n",
    "torch_model.eval()\n",
    "print(torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_restored_new = utils.load_checkpoint(restore_ckpt, torch_model)\n",
    "weights_dict = param_restored_new['state_dict']\n",
    "print(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"weights_files/\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(output_dir):\n",
    "    # Iterate over all the files in the directory\n",
    "    for filename in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            # Check if it's a file and delete it\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            # If it's a directory, delete the directory and its contents\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(f\"Directory {output_dir} does not exist.\")\n",
    "\n",
    "\n",
    "# Function to save the weights as binary files\n",
    "def save_weights_as_binary(weights_dict, output_dir):\n",
    "    for key, tensor in weights_dict.items():\n",
    "        # Convert the tensor to a NumPy array\n",
    "        np_array = tensor.cpu().numpy()\n",
    "\n",
    "        # Create a binary file name based on the tensor name\n",
    "        file_name = output_dir + key.replace('.', '_') + '.bin'\n",
    "\n",
    "        # Save the NumPy array as a binary file\n",
    "        np_array.tofile(file_name)\n",
    "        \n",
    "# Save all weights in the OrderedDict to binary files\n",
    "save_weights_as_binary(weights_dict, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the C++ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"weights_files/\"\n",
    "\n",
    "# Create an instance of the C++ GraphMetNetwork model\n",
    "cmodel = GraphMetNetwork()\n",
    "\n",
    "# Load the weights\n",
    "cmodel.load_weights(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_weights = 0\n",
    "for key, tensor in weights_dict.items():\n",
    "    # Convert the tensor to a NumPy array\n",
    "    np_array = tensor.cpu().numpy()\n",
    "\n",
    "    # Return cmodel function pointer to get the weight array\n",
    "    cmodel_weight_func_name = 'get_' + key.replace('.', '_')\n",
    "    cmodel_weight_func = getattr(cmodel, cmodel_weight_func_name)\n",
    "    cmodel_weight_array = cmodel_weight_func()\n",
    "    \n",
    "    # Compare Torch model weight with Cmodel weight\n",
    "    assert(np.allclose(np_array, cmodel_weight_array, atol=1e-5)), f'cmodel.{cmodel_weight_func_name} returned the wrong weights'\n",
    "    num_weights += 1\n",
    "\n",
    "print(f'Number of weights checked: {num_weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch_model(x_cont_test, x_cat_test, edge_index_test, batch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the C++ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmodel.GraphMetNetworkLayers(x_cont, x_cat, batch, num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert result from torch model to numpy arra\n",
    "np_results = results.detach().cpu().numpy()\n",
    "print(np_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(np_results, cmodel.get_output(), rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_results = cmodel.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l1deepmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
